# Final Project Report  
### Matthew Anderson, John Schroter  
### AI Hardware  
### 12/19/2025  
**Simulating Analog Weights for Low-Power AI (AIHWKIT)**  
https://github.com/Mircea-s-classes/ai-hardware-project-proposal-the-ai-hardware-group-project.git  

---

As modern AI models continue to grow across domains such as vision, language, audio, and sensor analytics, the fundamental bottleneck in digital hardware has shifted from computation to data movement. Most of the energy in AI systems is spent on transferring data between memory and compute, which becomes an issue especially for edge devices that have strict power ranges. Analog in-memory computing (IMC) combats this challenge by using memory arrays directly within the matrix multiplications, which significantly reduces data movement and allows large energy savings. Recent work, including studies by IBM and Nature, suggest that analog IMC can accelerate core deep learning operations, like transformer attention, while still keeping a strong and acceptable accuracy.

The goal of this project was to evaluate the usability of analog neural network training under realistic hardware using IBM’s AIHWKIT simulator. Specifically, we examined how analog noise and limited update precision affect the performance of a neural network and whether analog accuracy remains high enough for real-world edge applications where efficiency often outweighs small accuracy losses. To do this, we compared digital and analog implementations of the same model and conducted a large-scale sweep of analog hardware configurations.

We selected a two-layer multilayer perceptron (MLP) as our model architecture so that we could run 144 full analog training configurations in a reasonable timeframe. The network flattened each 28×28 MNIST image, projected the input through a 256-unit hidden layer with ReLU activation, and then classified it into 1 of 10 digits. This architecture was used identically for both digital and analog experiments to ensure that any differences in performance were attributable solely to analog hardware behavior. We used MNIST data that was loaded directly from raw IDX files that were included in our repository. All of the runs used the same training setup with 3 epochs, a batch size of 64, and a learning rate of 0.01. The digital model used standard GSD while analog models used AnalogSGD paired with the AIHWKIT’s analog parameter handling.

The core of the project was a sweep across three analog hardware parameters: forward noise, backward noise, and update precision. Forward and backward noise were varied from 0.0 to 1.0 in increments of 0.2, and update precision (desired_bl) took values of 1, 3, 5, and 7. This produced 144 distinct analog configurations, each evaluated after full training. The results showed that forward noise has the strongest negative impact on accuracy. When it exceeded roughly 0.4, performance declined rapidly. Backward noise had a milder effect but still reduced stability. Update precision played a major role as well, with higher values producing more reliable learning. Under extreme noise, some runs diverged entirely, yielding NaNs or collapsing to around ten percent accuracy which is essentially equivalent to random guessing.

Despite these challenges, the best analog configuration achieved a test accuracy of 90.63 percent with zero forward noise, zero backward noise, and the highest update precision. This is notable because many edge applications, including wearable activity recognition, keyword spotting, smart meter analytics, and low-resolution vision tasks, operate successfully in the 85–93 percent accuracy range. In such contexts, small accuracy reductions are acceptable if they yield substantial improvements in efficiency or battery life.

To contextualize the sweep, we also ran a controlled comparison between digital training, analog training in floating-point mode, and analog models with mild and harsh noise. The analog floating-point model performed nearly identically to the digital baseline, demonstrating that analog hardware can match digital accuracy when noise is low. Mild noise resulted in reasonable accuracy loss, while harsh noise degraded performance significantly. It is important to note that analog training appears slower only because the simulator runs analog operations digitally; actual analog hardware would operate much faster and at far lower energy cost, which further strengthens the case for analog IMC.

Overall, our results suggest that analog neural networks can achieve practical accuracy while offering the potential for dramatic energy reductions. These results align with the broader expectation that analog systems will be most beneficial for modalities requiring always-on or low-power operation. Vision models can exploit crossbar mappings of convolutional layers, NLP systems may benefit from analog attention modules, audio tasks can leverage high throughput per watt, and wearables naturally align with analog’s efficiency constraints. Although our work is limited to a small MLP and the MNIST dataset, it provides a meaningful initial map of how analog training behaves under a wide range of hardware conditions.

In conclusion, analog in-memory computing presents a compelling direction for the future of low-power AI. Our 144-configuration sweep highlights both the strengths and limitations of analog training and shows that analog models can reach accuracy levels appropriate for many edge applications even under realistic noise conditions. Future possibilities for this work include quantitative energy modeling from published crossbar data, looking into larger architectures such as CNNs and transformers, exploring long-term effects of weight drift for analog applications, evaluating hybrid analog-digital approaches, and building on our evaluations for more challenging datasets such as CIFAR-10 or TinyImageNet. Through these, we can continue to explore how analog computing is able to support scalable and energy-efficient AI workloads.
